## Units 1–3: Forum Reflection – Agent‑Based Systems in Organisations

### Summary of Activity  
We examined why Agent‑Based Systems (ABS) rose alongside organisational complexity and the limits of centralised architectures. I argued that agent‑oriented programming enables autonomous, proactive agents that scale and adapt (Cardoso and Ferrando, 2021), and framed ABS within ABM&S for organisational design and risk‑free scenario testing (Cannavacciuolo et al., 2024). Evidence from megaprojects showed how ABM investigates collaboration and innovation outcomes (Zhao et al., 2022). Peers highlighted validation, scalability, and hybrid modelling concerns (Railsback and Grimm, 2019; Davis et al., 2007; Sterman, 2000).
  
### Key Concepts & Insights  
- **Emergence & Design Exploration** – bottom‑up behaviours for organisational structure testing (Epstein and Axtell, 1996; Tesfatsion, 2006).  
- **Methodological Rigor** – calibration/validation to avoid misleading emergence (Heath, Hill and Ciarallo, 2009; Railsback and Grimm, 2019).  
- **Hybrid & Governance** – ABS with system dynamics; accountability for autonomous behaviour (Davis et al., 2007; Sterman, 2000; Bryson and Theodorou, 2019; Rahwan et al., 2019).

###  Reflection  
I now see ABS as powerful but conditional: value depends on disciplined specification, validation, and—in some contexts—hybridisation. Governance and explainability matter as autonomy grows (Cardoso and Ferrando, 2021; Cannavacciuolo et al., 2024).


See [References.md](./References.md) for a complete list of sources used throughout these reflections.

---

## Units 5–7: Forum Reflection – Agent Communication (KQML, KIF) & Practice

### Summary of Activity  
We contrasted method invocation with intent‑centric dialogue in Agent Communication Languages (ACLs). KQML performatives (e.g., *ask*, *tell*, *achieve*) combined with KIF content enable heterogeneous agents to coordinate via shared semantics (Finin, Labrou and Mayfield, 1994; Genesereth and Ketchpel, 1994; Labrou and Finin, 1997; Wooldridge, 2009). Discussion covered ontology alignment, formal verification, and learning‑enhanced cooperation (Luo, Zou and Luo, 2012; Panait and Luke, 2005; Busoniu, Babuska and De Schutter, 2008), plus LLM‑enabled extensions (Kim, Lee and Mutlu, 2024).

### Key Concepts & Insights  
- **Protocol vs. Semantics** – KQML handles *how* to communicate; KIF captures *what* is meant (Finin, Labrou and Mayfield, 1994; Labrou and Finin, 1997).  
- **Meaning Stability** – ontology engineering/semantic‑web practices to reduce drift (Gómez‑Pérez, Fernández‑López and Corcho, 2020).  
- **Adaptation & Accountability** – cooperative learning and commitment‑based interaction for robust coordination (Panait and Luke, 2005; Busoniu, Babuska and De Schutter, 2008; Singh, Chopra and Desai, 2013).

###  Reflection  
I moved from viewing ACLs as theoretical to seeing them as socio‑technical: semantics plus engineered ontologies for stability, learning for adaptability, and explicit commitments for accountability (Wooldridge, 2009; Gómez‑Pérez, Fernández‑López and Corcho, 2020).


See [References.md](./References.md) for a complete list of sources used throughout these reflections.

---

## Units 9–11: Forum Reflection – Deep Learning Ethics & Governance

### Summary of Activity  
We explored how generative deep learning heightens issues around bias, authorship, and misinformation. Studies show image models can reproduce stereotypes from skewed data (Sun et al., 2023), while debates over provenance/attribution challenge copyright regimes for AI outputs (Zhou and Nabus, 2023; Elgammal, 2023). Deepfakes undermine epistemic trust (ACM, 2024; Brennan, 2023; Zhang, Wang and Singh, 2022; Thomson et al., 2025). The thread converged on lifecycle governance, documentation, and audits (Floridi and Cowls, 2021; Mitchell et al., 2019; Raji et al., 2020).

### Key Concepts & Insights  
- **Bias & Harm** – dataset skew → stereotyping; need for evaluation and mitigation (Sun et al., 2023; Bender et al., 2021).  
- **Authorship & Provenance** – clarify creative contribution and track origins (Zhou and Nabus, 2023; Elgammal, 2023).  
- **Authenticity & Accountability** – combine technical and institutional responses (ACM, 2024; Mitchell et al., 2019; Raji et al., 2020).

###  Reflection  
Benefits are real, but durable value requires transparency, provenance, media authenticity infrastructure, and independent auditing—embedding governance as deeply as the models themselves (Floridi and Cowls, 2021; Raji et al., 2020).

See [References.md](./References.md) for a complete list of sources used throughout these reflections.

