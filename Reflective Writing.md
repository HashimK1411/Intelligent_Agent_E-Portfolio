title: "Reflective Essay: End of Module Assignment" author: "" date: ""

Link to e-Portfolio: CLICK HERE (to edit accordingly)
Table of Contents
Designing the Academic Research Online Agent

WHAT: The Journey and the Project

SO WHAT: Emotions, Reflection, and Critical Learning

NOW WHAT: Growth, Skills, and Future Impact

Conclusion

References

Designing the Academic Research Online Agent
WHAT: The Journey and the Project
The Intelligent Agents module was one of the most intellectually stimulating yet demanding experiences of this degree. It offered not only technical insight into agent-based computing but also an opportunity to reflect deeply on collaboration, resilience, and purpose. The group project, Academic Research Online Agent, aimed to automate academic metadata retrieval using multiple APIs such as arXiv, Crossref, and DOAJ. It was an ambitious attempt to combine autonomy, coordination, and reasoning in one intelligent system and in many ways, it mirrored the dynamics of a real team.

The project was structured around the Belief–Desire–Intention (BDI) model (Wooldridge, 2009), where each agent possessed specific responsibilities: discovering research queries, fetching and extracting results, and storing data systematically. My personal contribution centred on documenting the system workflow, validating API outputs, and testing integration between the Fetch and Extract agents.

Working shifts as a cybersecurity analyst alongside this project was a challenge that tested endurance. There were nights when mental exhaustion made it difficult to switch from analysing threat logs to debugging code. Yet, teamwork became the driving force that kept the project alive. The empathy and communication within the group created a sense of shared purpose and an environment where mutual encouragement replaced pressure. The experience reaffirmed that collaboration, much like an agent system, functions best when autonomy and trust operate side by side.

SO WHAT: Emotions, Reflection, and Critical Learning
Emotionally, this project was a lesson in balance; between work and study, pressure and patience, individuality and teamwork. There were moments of frustration when API requests failed or agent scripts looped endlessly. These instances triggered not only technical analysis but also self-reflection. According to Gibbs (1988), recognising frustration as part of the learning process helps transform stress into motivation, and that was exactly what happened here.

Initially, the BDI model felt abstract, its components such as beliefs, desires, and intentions were more philosophical than practical. Through collaborative debugging sessions and late-night conversations with teammates, understanding began to form. The abstract logic of the model evolved into something tangible; each line of code mirrored cognitive reasoning. The transformation from confusion to clarity was deeply satisfying. It also reflected Kolb’s (1984) experiential learning cycle, where learning emerges through doing, reflecting, and adapting.

The process also challenged preconceptions about independence. Before this module, I viewed technical competence as a largely individual pursuit. Yet, this project proved that collaboration enhances not only performance but understanding. When someone explained a concept differently, it revealed new angles of thinking. Schön (1983) describes this as reflection-in-action, where we adapt our approach based on real-time feedback. In hindsight, the module became less about agents themselves and more about learning how people, like agents, thrive when communication and cooperation are strong.

The ethical choices made during the project further shaped professional awareness. Choosing to use official APIs rather than scraping data emphasised respect for data ownership and transparency. It connected technical responsibility with moral clarity, aligning with Floridi and Cowls’ (2021) call for value-driven AI design. Every design decision became an ethical one, and that realisation deepened both technical and human understanding.

NOW WHAT: Growth, Skills, and Future Impact
This experience changed how intelligent systems, and teamwork are viewed in a professional context. Technically, it reinforced the understanding that agent reasoning, autonomy, and coordination form the foundation of many cybersecurity applications. In a Security Operations Centre (SOC), for example, monitoring tools act like agents, detecting anomalies, sharing information, and triggering actions. The logic behind our project now informs how automation scripts and playbook workflows can be improved to operate proactively rather than reactively (Wallace and Ali, 2025).

The project also strengthened documentation, testing, and problem-solving skills. But more importantly, it developed emotional resilience and time management under pressure. Working twelve-hour shifts while meeting deadlines required not only discipline but self-compassion and learning when to pause and recalibrate. That balance between persistence and rest has now become an integral professional lesson.

Equally transformative was the development of interpersonal awareness. Coordinating with teammates across time zones taught adaptability, empathy, and patience; qualities that make collaboration meaningful. As Dingsøyr, Moe and Seim (2018) note, knowledge coordination, rather than competition, sustains collective success. The team’s diversity of skills made problem-solving not only faster but more enjoyable, turning what began as coursework into a shared exploration of curiosity and creativity.

This project also sparked curiosity about future learning directions. Reading Jang et al. (2023) on structured prompting in BDI agents inspired the idea of integrating reinforcement learning into cybersecurity automation, allowing systems to adapt, not just react. The idea of an intelligent agent that learns from threat patterns is not just exciting; it feels achievable, thanks to the grounding this module provided.

Conclusion
Reflecting on this module feels like revisiting a journey that was as much about people as it was about code. The Intelligent Agents project deepened technical knowledge but, more importantly, cultivated humility and empathy. It revealed that the intelligence behind systems often begins with the intelligence of collaboration, understanding, listening, and adapting.

The late nights spent switching from cybersecurity logs to debugging agent scripts were not easy, but they became a quiet testament to perseverance. The project taught that intelligence, whether human or artificial, is not defined by speed or logic alone, but by the capacity to learn, reflect, and cooperate.

If one lasting message remains from this experience, it is that intelligent systems should mirror intelligent humanity. Building autonomous agents is not just about programming behaviour, but about designing trust, ethics, and empathy into the architecture of technology. That, perhaps, is the real lesson and the one that stays long after the code has run.

References
Bramer, W.M. et al. (2018) ‘A systematic approach to searching: an efficient and complete method to develop literature searches’, Journal of the Medical Library Association, 106(4), pp. 531–541.

Dingsøyr, T., Moe, N.B. and Seim, E.A. (2018) ‘Coordinating knowledge work in multiteam programmes’, Project Management Journal, 49(6), pp. 64–77.

Floridi, L. and Cowls, J. (2021) A Unified Framework of Five Principles for AI in Society. Oxford Internet Institute.

Gibbs, G. (1988) Learning by Doing: A Guide to Teaching and Learning Methods. Oxford: Oxford Polytechnic.

Jang, M. et al. (2023) ‘A structured prompting based on belief–desire–intention model for proactive and explainable task planning’, International Conference on Human-Agent Interaction, pp. 375–377.

Jennings, N.R., Sycara, K. and Wooldridge, M. (1998) ‘A roadmap of agent research and development’, Autonomous Agents and Multi-Agent Systems, 1(1), pp. 7–38.

Kolb, D.A. (1984) Experiential Learning: Experience as the Source of Learning and Development. Englewood Cliffs: Prentice Hall.

Schön, D.A. (1983) The Reflective Practitioner: How Professionals Think in Action. London: Temple Smith.

Wallace, G. and Ali, N. (2025) ‘The Future of SOC Operations: Autonomous Cyber Defence with AI and Machine Learning’.

Wooldridge, M. (2009) An Introduction to MultiAgent Systems. 2nd edn. Chichester: John Wiley & Sons.
